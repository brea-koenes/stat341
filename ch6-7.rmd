---
title: "ch6-7.rmd"
author: "Brea Koenes"
date: "10/24/2022"
output: html_document
---

```{r setup, include=FALSE}
# Load packages
library(bayesrules)
library(tidyverse)
library(ggformula)
library(dplyr)
```

# Chapter 6

## 5

a.

```{r}
# Define grid
grid_data <- data.frame(pi_grid = seq(from = 0, to = 1, length = 5))

# Evaluate the prior & likelihood at each pi
grid_data <- grid_data %>% 
  mutate(prior = dbeta(pi_grid, 3, 8),
         likelihood = dbinom(2, 10, pi_grid))

# Approximate the posterior
grid_data <- grid_data %>% 
  mutate(unnormalized = likelihood * prior,
         posterior = unnormalized / sum(unnormalized))

set.seed(84735)

# Sample from the discretized posterior
post_sample <- sample_n(grid_data, size = 10000, 
                        weight = posterior, replace = TRUE)
```

b.

```{r}
# Define grid
grid_data <- data.frame(pi_grid = seq(from = 0, to = 1, length = 201))

# Evaluate the prior & likelihood at each pi
grid_data <- grid_data %>% 
  mutate(prior = dbeta(pi_grid, 3, 8),
         likelihood = dbinom(2, 10, pi_grid))

# Approximate the posterior
grid_data <- grid_data %>% 
  mutate(unnormalized = likelihood * prior,
         posterior = unnormalized / sum(unnormalized))

set.seed(84735)

# Sample from the discretized posterior
post_sample <- sample_n(grid_data, size = 10000, 
                        weight = posterior, replace = TRUE)
```

## 6

a.

```{r}
# Define grid
grid_data   <- data.frame(lambda_grid = seq(from = 0, to = 8, length = 9))

# Evaluate prior & likelihood
grid_data <- grid_data %>% 
  mutate(prior = dgamma(lambda_grid, 20, 5),
         likelihood = dpois(2, lambda_grid) * dpois(8, lambda_grid))

# Approximate posterior
grid_data <- grid_data %>% 
  mutate(unnormalized = likelihood * prior,
         posterior = unnormalized / sum(unnormalized))

set.seed(84735)

# Sample from the discretized posterior
post_sample <- sample_n(grid_data, size = 10000, 
                        weight = posterior, replace = TRUE)

# Histogram of the grid simulation with posterior pdf 
ggplot(post_sample, aes(x = lambda_grid)) + 
  geom_histogram(aes(y = ..density..), color = "white") + 
  stat_function(fun = dgamma, args = list(20, 5)) + 
  lims(x = c(0, 8))
```

b.

```{r}
# Define grid 
grid_data   <- data.frame(lambda_grid = seq(from = 0, to = 8, length = 201))

# Evaluate prior & likelihood
grid_data <- grid_data %>% 
  mutate(prior = dgamma(lambda_grid, 20, 5),
         likelihood = dpois(2, lambda_grid) * dpois(8, lambda_grid))

# Approximate the posterior
grid_data <- grid_data %>% 
  mutate(unnormalized = likelihood * prior,
         posterior = unnormalized / sum(unnormalized))

set.seed(84735)

# Sample from the discretized posterior
post_sample <- sample_n(grid_data, size = 10000, 
                        weight = posterior, replace = TRUE)

# Histogram of the grid simulation with posterior pdf 
ggplot(post_sample, aes(x = lambda_grid)) + 
  geom_histogram(aes(y = ..density..), color = "white") + 
  stat_function(fun = dgamma, args = list(20, 5)) + 
  lims(x = c(0, 8))
```

## modified 7

```{r}
library(ggformula)

gf_dist('gamma', shape = 2, rate = 2)
```

```{r}
# define grid
grid <- expand.grid(
  mu = seq(4, 16, by=4), 
  sigma = seq(1, 4, by=1))

# to be continued...
```

## 13

a.

```{r}
# Define model
bb_model <- "
  data {
    int<lower = 0, upper = 10> Y;
  }
  parameters {
    real<lower = 0, upper = 1> pi;
  }
  model {
    Y ~ binomial(10, pi);
    pi ~ beta(3, 8);
  }
"
```

```{r echo=FALSE}
# Simulate the posterior
require(rstan)
bb_sim <- stan(model_code = bb_model, data = list(Y = 2), 
               chains = 3, iter = 12000, seed = 84735)
```

b.

```{r}
require(bayesplot)
mcmc_trace(bb_sim, pars = "pi", size = 0.1)
```

c. 

The range is 0 to 6000. The end of the range is not 12000, but rather 6000 calculated by 6000*2. 

d. 

```{r}
# Density plot of the Markov chain values
mcmc_dens(bb_sim, pars = "pi") + 
  yaxis_text(TRUE) + 
  ylab("density")
```

e. 

```{r}
bayesrules::summarize_beta(alpha = 3, beta = 8)
```

```{r}
summarize_normal_normal(mean = 8, sd = .13, sigma = pi, y_bar = 8.27, n = 10)
```

My MCMC approximation is very similar to the results from the posterior model of pi. They have a similar mode. 

## 16

a. 

```{r}
# Define model
gp_model <- "
  data {
    int<lower = 0> Y[3];
  }
  parameters {
    real<lower = 0> lambda;
  }
  model {
    Y ~ poisson(lambda); 
    lambda ~ gamma(5, 5);
  }
"

# Simulate the posterior
gp_sim <- stan(model_code = gp_model, data = list(Y = c(0,1,0)), 
               chains = 4, iter = 10000, seed = 84735)
```

b.

```{r}
# Trace plots of the 4 Markov chains
mcmc_trace(gp_sim, pars = "lambda", size = 0.1)

# Density plot of the Markov chain values
mcmc_dens(gp_sim, pars = "lambda") + 
  yaxis_text(TRUE) + 
  ylab("density")
```

c.

The most plausible posterior appears to be about 0.65.

d. 

```{r}
summarize_gamma_poisson(shape = 5, rate = 5, sum_y = 1, n = 3)
```

My MCMC approximation is closer to the prior than approximating using a posterior model. 

## modified 17

```{r}
data <- c(7.1,8.9,8.4,8.6)

plot_normal_likelihood(y = data, sigma = 0.5)
```

to be continued...

# Chapter 7

## 6

a.

```{r}
current <- 4.6

set.seed(84735)

proposal <- runif(1, min = current - 2, max = current + 2)
proposal
```

b.

```{r}
current <- 2.1

set.seed(84735)

proposal <- runif(1, min = current - 7, max = current + 7)
proposal
```

c. 

```{r}
current <- 8.9

set.seed(84735)

proposal <- runif(1, min = current - 2, max = current + 2)
proposal
```

d. 

```{r}
current <- 1.2

set.seed(84735)

proposal <- runif(1, min = current - 0.5, max = current + 0.5)
proposal
```

e.

```{r}
current <- 7.7

set.seed(84735)

proposal <- runif(1, min = current - 3, max = current + 3)
proposal
```

## 7

a.

b.

c.

d.

e.

## 8

a.

b.

c.

d.

e.

## 10

a.

```{r}
one_mh_iteration <- function(w, current){
 # STEP 1: Propose the next chain location
 proposal <- runif(1, min = current - w, max = current + w)
  
 # STEP 2: Decide whether or not to go there
 proposal_plaus <- dnorm(proposal, 0, 1) * dnorm(6.25, proposal, 0.75)
 current_plaus  <- dnorm(current, 0, 1) * dnorm(6.25, current, 0.75)
 alpha <- min(1, proposal_plaus / current_plaus)
 next_stop <- sample(c(proposal, current), 
                     size = 1, prob = c(alpha, 1-alpha))
  
 # Return the results
 return(data.frame(proposal, alpha, next_stop))
}
```

```{r}
mh_tour <- function(N, w){
  # 1. Start the chain at location 3
  current <- 3

  # 2. Initialize the simulation
  mu <- rep(0, N)

  # 3. Simulate N Markov chain stops
  for(i in 1:N){    
    # Simulate one iteration
    sim <- one_mh_iteration(w = w, current = current)
    
    # Record next location
    mu[i] <- sim$next_stop
    
    # Reset the current location
    current <- sim$next_stop
  }
  
  # 4. Return the chain locations
  return(data.frame(iteration = c(1:N), mu))
}
```

```{r}
set.seed(84735)
mh_simulation_1 <- mh_tour(N = 50, w = 50)
```

```{r}
ggplot(mh_simulation_1, aes(x = iteration, y = mu)) + 
  geom_line()
```

b.

```{r}
one_mh_iteration <- function(w, current){
 # STEP 1: Propose the next chain location
 proposal <- runif(1, min = current - w, max = current + w)
  
 # STEP 2: Decide whether or not to go there
 proposal_plaus <- dnorm(proposal, 0, 1) * dnorm(6.25, proposal, 0.75)
 current_plaus  <- dnorm(current, 0, 1) * dnorm(6.25, current, 0.75)
 alpha <- min(1, proposal_plaus / current_plaus)
 next_stop <- sample(c(proposal, current), 
                     size = 1, prob = c(alpha, 1-alpha))
  
 # Return the results
 return(data.frame(proposal, alpha, next_stop))
}
```

```{r}
mh_tour <- function(N, w){
  # 1. Start the chain at location 3
  current <- 3

  # 2. Initialize the simulation
  mu <- rep(0, N)

  # 3. Simulate N Markov chain stops
  for(i in 1:N){    
    # Simulate one iteration
    sim <- one_mh_iteration(w = w, current = current)
    
    # Record next location
    mu[i] <- sim$next_stop
    
    # Reset the current location
    current <- sim$next_stop
  }
  
  # 4. Return the chain locations
  return(data.frame(iteration = c(1:N), mu))
}
```

```{r}
set.seed(84735)
mh_simulation_1 <- mh_tour(N = 50, w = 0.1)
```

```{r}
ggplot(mh_simulation_1, aes(x = iteration, y = mu)) + 
  geom_line()
```

c.

```{r}
one_mh_iteration <- function(w, current){
 # STEP 1: Propose the next chain location
 proposal <- runif(1, min = current - w, max = current + w)
  
 # STEP 2: Decide whether or not to go there
 proposal_plaus <- dnorm(proposal, 0, 1) * dnorm(6.25, proposal, 0.75)
 current_plaus  <- dnorm(current, 0, 1) * dnorm(6.25, current, 0.75)
 alpha <- min(1, proposal_plaus / current_plaus)
 next_stop <- sample(c(proposal, current), 
                     size = 1, prob = c(alpha, 1-alpha))
  
 # Return the results
 return(data.frame(proposal, alpha, next_stop))
}
```

```{r}
mh_tour <- function(N, w){
  # 1. Start the chain at location 3
  current <- 3

  # 2. Initialize the simulation
  mu <- rep(0, N)

  # 3. Simulate N Markov chain stops
  for(i in 1:N){    
    # Simulate one iteration
    sim <- one_mh_iteration(w = w, current = current)
    
    # Record next location
    mu[i] <- sim$next_stop
    
    # Reset the current location
    current <- sim$next_stop
  }
  
  # 4. Return the chain locations
  return(data.frame(iteration = c(1:N), mu))
}
```

```{r}
set.seed(84735)
mh_simulation_1 <- mh_tour(N = 1000, w = 50)
```

```{r}
ggplot(mh_simulation_1, aes(x = iteration, y = mu)) + 
  geom_line()
```

d.

```{r}
one_mh_iteration <- function(w, current){
 # STEP 1: Propose the next chain location
 proposal <- runif(1, min = current - w, max = current + w)
  
 # STEP 2: Decide whether or not to go there
 proposal_plaus <- dnorm(proposal, 0, 1) * dnorm(6.25, proposal, 0.75)
 current_plaus  <- dnorm(current, 0, 1) * dnorm(6.25, current, 0.75)
 alpha <- min(1, proposal_plaus / current_plaus)
 next_stop <- sample(c(proposal, current), 
                     size = 1, prob = c(alpha, 1-alpha))
  
 # Return the results
 return(data.frame(proposal, alpha, next_stop))
}
```

```{r}
mh_tour <- function(N, w){
  # 1. Start the chain at location 3
  current <- 3

  # 2. Initialize the simulation
  mu <- rep(0, N)

  # 3. Simulate N Markov chain stops
  for(i in 1:N){    
    # Simulate one iteration
    sim <- one_mh_iteration(w = w, current = current)
    
    # Record next location
    mu[i] <- sim$next_stop
    
    # Reset the current location
    current <- sim$next_stop
  }
  
  # 4. Return the chain locations
  return(data.frame(iteration = c(1:N), mu))
}
```

```{r}
set.seed(84735)
mh_simulation_1 <- mh_tour(N = 1000, w = 0.1)
```

```{r}
ggplot(mh_simulation_1, aes(x = iteration, y = mu)) + 
  geom_line()
```

e.

"w" is the the Uniform half-width. Due to this, it makes sense that a w value will result in a more detailed plot. A larger w will result in a chunkier plot with less detail across iterations. This can be seen in comparing a and b. a, with a larger w, is has a chunky, stark line. b has much more detail and variation across the line, as it has a smaller w.

f.

Having a low w is important in scenarios with more iterations. As seen in c and d, plot d has much more detail and gives us more information about the variation between iterations than c doesâ€”it has a low w. 

## 12

a.

b.

c.

d.

e.

f.

## 14

a.

b.

c.

d.

## 15 

prior: proportion of emails I receive 24 hours: 19/24

```{r}
one_mh_iteration <- function(w, current){
 # STEP 1: Propose the next chain location
 proposal <- runif(1, min = current - w, max = current + w)
  
 # STEP 2: Decide whether or not to go there
 proposal_plaus <- dnorm(proposal, 0, 1) * dnorm(6.25, proposal, 0.75)
 current_plaus  <- dnorm(current, 0, 1) * dnorm(6.25, current, 0.75)
 alpha <- min(1, proposal_plaus / current_plaus)
 next_stop <- sample(c(proposal, current), 
                     size = 1, prob = c(alpha, 1-alpha))
  
 # Return the results
 return(data.frame(proposal, alpha, next_stop))
}
```

```{r}
mh_tour <- function(N, w){
  # start the chain at 19 emails
  current <- 19

  # initialize the simulation
  mu <- rep(0, N)

  # simulate N Markov chain stops
  for(i in 1:N){    
    # Simulate one iteration
    sim <- one_mh_iteration(w = w, current = current)
    
    # record next email
    mu[i] <- sim$next_stop
    
    # reset the current email
    current <- sim$next_stop
  }
  
  # return the chain emails
  return(data.frame(iteration = c(1:N), mu))
}

#  simulate a Markov chain tour of length 2000
set.seed(84735)
mh_simulation_1 <- mh_tour(N = 2000, w = pi)

# plot
ggplot(mh_simulation_1, aes(x = iteration, y = mu)) + 
  geom_line()

ggplot(mh_simulation_1, aes(x = mu)) + 
  geom_histogram(aes(y = ..density..), color = "white", bins = 20) + 
  stat_function(fun = dnorm, args = list(4,0.6), color = "blue")
```

The trace plot (left) illustrates the email or sequence of emails stops. The histogram (right) illustrates the relative amount of emails per day.
