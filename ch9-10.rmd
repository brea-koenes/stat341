---
title: "R Notebook"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
# Load packages
library(bayesrules)
library(tidyverse)
library(ggformula)
library(dplyr)
library(bayesplot)
library(tidybayes)
library(posterior)
library(janitor)
library(rstan)
library(broom.mixed)
```

# Chapter 9

## 9.9

a.  

```{r}
summarize_normal_normal(mean = 1000, sd = 2000, sigma = 10,
                        y_bar = 9000, n = 10000)
```

b.  

```{r}
require(rstanarm)

model <- stan_glm(
  rides ~ humidity, data = bikes, 
  family = gaussian,
  prior_PD = TRUE,
  prior_intercept = normal(1000, 2000, autoscale = TRUE),
  prior = normal(0, 10, autoscale = TRUE), 
  prior_aux = exponential(1, autoscale = TRUE),
  chains = 5, iter = 8000, seed = 84735)
```

c.  

```{r}
require(bayesplot)

# Trace plots of parallel chains
mcmc_trace(model, size = .1)

# Density plots of parallel chains
mcmc_dens_overlay(model)
```

d.  

Ridership decreases as humidity increases. There is much variability with the ridership per day, so that impacts the strength of the relationship.

## 9.10

a.  

```{r}
# Load and plot data
data(bikes)
ggplot(bikes, aes(x = humidity, y = rides)) + 
  geom_point(size = 0.5) + 
  geom_smooth(method = "lm", se = FALSE)
```

b.  

The data is normally distributed enough; the points are fairly evenly distributed across the y-axis. Since it doesn't form a trumpet-like shape, it could be fine for Normal regression.

## 9.11

a.  

```{r}
bike_model <- stan_glm(rides ~ humidity, data = bikes, 
  family = gaussian,
  prior_PD = FALSE,
  prior_intercept = normal(1000, 2000, autoscale = TRUE),
  prior = normal(0, 10, autoscale = TRUE), 
  prior_aux = exponential(1, autoscale = TRUE),
  chains = 5, iter = 4000*2, seed = 84735)
```

b.  

```{r}
# Effective sample size ratio 
neff_ratio(bike_model)
```

```{r}
# Density plots of parallel chains
mcmc_dens_overlay(bike_model)
```

Given the results above, we can trust these simulation results.

c.  

```{r}
# Trace plots of parallel chains
mcmc_trace(bike_model, size = .1)
```

The sigma is more centered than 9.9's and the scales are much different.

## 9.12

a.  

```{r}
tidy(bike_model, effects = c("fixed", "aux"),
     conf.int = TRUE, conf.level = 0.95)
```

b.  

The posterior median relationship is 3935.315 - 8.128. That means for every one degree increase in humidity, we expect ridership to decrease by about 8 rides.

c.  

The CI represents the uncertainty in the relationship. $$\beta_1$$ (-16.16035,1.899641) indicates that this slope could range anywhere between about -16 and 2.

d.  

I would say that we have alright posterior evidence that there's a negative association between ridership and humidity. The standard error is low enough for it to carry some weight, but not low enough for there to be very certain evidence to their relationship. However, the CI is a small range, so that does help the credibility of the evidence of their relationship.

## 9.16

a.  

```{r}
summary(penguins_bayes)
```


```{r}
penguins_model <- stan_glm(flipper_length_mm ~ bill_length_mm, data = penguins_bayes,
                       family = gaussian,
                       prior_PD = TRUE, 
                       prior_intercept = normal(43.92, 11.82),
                       prior = normal(200.9, 28.9), 
                       prior_aux = exponential(0.0008),
                       chains = 4, iter = 10000*2, seed = 84735)
```

b.  

```{r}
prior_summary(penguins_model)
```

c.  

```{r}
# Trace plots of parallel chains
mcmc_trace(penguins_model, size = 0.1)
```

d.  

It looks like flipper and bill length may be negatively associated.

## 9.17

a.  

```{r}
penguins_bayes |>
  ggplot(aes(x = flipper_length_mm, y = bill_length_mm)) +
  geom_point()
```

There appears to be a positive linear relationship between flipper and bill length.

b.  

It meets the conditions for a simple normal regression model. It has linearity on the plot above. If it also has independent observations and is normally distributed on a fitted vs resids plot, we can use a normal model.

## 9.18

a.  

```{r}
penguins_post_model <- stan_glm(flipper_length_mm ~ bill_length_mm, data = penguins_bayes,
                       family = gaussian,
                       prior_intercept = normal(43.92, 11.82),
                       prior = normal(200.9, 28.9), 
                       prior_aux = exponential(0.0008),
                       chains = 4, iter = 10000*2, seed = 84735)
```

b.  

```{r}
# Trace plots of parallel chains
mcmc_trace(penguins_post_model, size = 0.1)
```

c.  

```{r}
tidy(penguins_post_model, conf.int = TRUE, conf.level = 0.90)
```

d.  

There is a 90% probability that the true bill_length_mm lies within .1.5-.1.9. 

e.  

There is a decent standard error, so I'm wary to say that we have enough evidence that they are related.

# Chapter 10

## 10.7

a.  

```{r problem7}
problem7_data <- 
  tibble(
    x = c(12,10,4,8,6), 
    y = c(20,17,4,11,9)
  )
```

$$

y=mx+b \\

y= \beta\_1x+\beta\_0 \\

y= \beta\_0 + \beta\_1x \\

\hat{y}\_i= \beta\_0 + \beta\_1 x_i \\

\hat{y}\_1= -1.8 + 2.1 \cdot 12 \\

\hat{y}\_2= -1.8 + 2.1 \cdot 10 \\

$$

b.  

```{r}
problem7_data |>
  mutate(y_hat=-1.8+2.1*x, 
         y_model=-1.8+2.1*x+rnorm(5,0,0.8),
         y_model2=rnorm(5,-1.8+2.1*x,0.8)
        )
```

## 10.13

a.  

```{r}
head(coffee_ratings)
```

It likely violates the independence assumption due to aroma and aftertaste not being completely independent. Also, other variables come into play, such as sweetness, clean_cup, and acidity.

b.  

```{r}
set.seed(84735)
new_coffee <- coffee_ratings %>% 
  group_by(farm_name) %>% 
  sample_n(1) %>% 
  ungroup()
dim(new_coffee)
```

## 10.14

a.  

```{r}
ggplot(new_coffee, aes(x = aroma, y = total_cup_points)) + 
  geom_point(size = 0.5) + 
  geom_smooth(method = "lm", se = FALSE)
```

b.  

```{r}
summary(new_coffee)
```

```{r}
coffee_model <- stan_glm(total_cup_points ~ aroma, data = new_coffee,
                       family = gaussian,
                       prior_intercept = normal(7.5, 1.2),
                       prior = normal(82.10, 30), 
                       prior_aux = exponential(0.0008),
                       chains = 4, iter = 10000*2, seed = 84735)
```

c.  

```{r}
mcmc_trace(coffee_model, size = 0.1)
```

d.  

```{r}
summary(coffee_model)
```

e.  

Aroma and rating are associated. The better a coffee's aroma is, the rating is likely to be better as well.

## 10.15

a.  

b.  

c.  

d.  

## 10.16

a.  

b.  

c.  

d.  

## 10.17

a.  

b.  

c.  

## 10.18

## 10.19

a.  

b.  

c.  

d.  
